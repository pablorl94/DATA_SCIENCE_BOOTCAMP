{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILMAFFINITY - Data extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Scraper class\n",
    "\n",
    "class FilmaffinityScraper():\n",
    "    \n",
    "    \"\"\"A small scraper to extract data from Filmaffinity's movie database.\"\"\"\n",
    "    \n",
    "    def __init__(self, path=\"./chromedriver\", wait_time=3):\n",
    "        \"The path of the webdriver and the time that will take the explicit wait.\"\n",
    "        self.path = path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "        self.wait_time = wait_time\n",
    "        self.wait = WebDriverWait(self.driver, self.wait_time)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"Repr format of the scraper object.\"\n",
    "        return f\"FilmaffinityScraper(path = '{self.path}', wait_time = {self.wait_time})\"\n",
    "    \n",
    "    def get_advanced_search(self):\n",
    "        \"Get the Filmaffinity's advanced search url.\"\n",
    "        url = \"https://www.filmaffinity.com/es/advsearch.php\"\n",
    "        self.driver.get(url)\n",
    "        \n",
    "    def search_by_text(self, text=\"\", title=True, director=False, cast=False, \n",
    "                       script=False, photo=False, music=False, producer=False):\n",
    "        \"Filter Filmaffinity's database by text.\"\n",
    "        checkbox = [\"title\", \"director\", \"cast\", \"script\", \"photo\", \"music\", \"producer\"]\n",
    "    \n",
    "        self.wait.until(EC.presence_of_element_located((By.ID, \"text-option-container\")))\n",
    "        text_search = self.driver.find_element(By.ID, \"text-option-container\")\n",
    "    \n",
    "        if text:\n",
    "            text_input = text_search.find_element(By.NAME, \"stext\")\n",
    "            text_input.clear()\n",
    "            text_input.send_keys(text)\n",
    "    \n",
    "        for category in checkbox:\n",
    "            if category == \"title\" and not title:\n",
    "                text_search.find_element(By.CSS_SELECTOR, f\"input[value={category}]\").click()\n",
    "            elif category != \"title\" and eval(category):\n",
    "                text_search.find_element(By.CSS_SELECTOR, f\"input[value={category}]\").click()\n",
    "                \n",
    "    def select_country(self, country_code):\n",
    "        \"Filter Filmaffinity's database by country.\"\n",
    "        self.wait.until(EC.presence_of_element_located((By.ID, \"country\")))\n",
    "        country = Select(self.driver.find_element(By.ID, \"country\"))\n",
    "        country.select_by_value(country_code)\n",
    "    \n",
    "    def select_genre(self, genre_code):\n",
    "        \"Filter Filmaffinity's database by genre.\"\n",
    "        self.wait.until(EC.presence_of_element_located((By.NAME, \"genre\")))\n",
    "        genre = Select(self.driver.find_element(By.NAME, \"genre\"))\n",
    "        genre.select_by_value(genre_code)\n",
    "    \n",
    "    def select_from_to_year(self, fromyear_code, toyear_code):\n",
    "        \"Filter Filmaffinity's database by period.\"\n",
    "        self.wait.until(EC.presence_of_element_located((By.NAME, \"fromyear\")))\n",
    "        fromyear = Select(self.driver.find_element(By.NAME, \"fromyear\"))\n",
    "        fromyear.select_by_visible_text(fromyear_code)\n",
    "        \n",
    "        self.wait.until(EC.presence_of_element_located((By.NAME, \"toyear\")))\n",
    "        toyear = Select(self.driver.find_element(By.NAME, \"toyear\"))\n",
    "        toyear.select_by_visible_text(toyear_code)\n",
    "    \n",
    "    def search_selection(self):\n",
    "        \"Search the selection.\"\n",
    "        self.wait.until(EC.presence_of_element_located((By.ID, \"adv-search-button\")))\n",
    "        search = self.driver.find_element(By.ID, \"adv-search-button\")\n",
    "        search.send_keys(Keys.RETURN)\n",
    "        \n",
    "    def get_urls(self):\n",
    "        \"Get the urls from a selection of movies.\"\n",
    "        try:\n",
    "            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.mc-title [href]\")))\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        movies = self.driver.find_elements(By.CSS_SELECTOR, \"div.mc-title [href]\")\n",
    "        urls = [movie.get_attribute(\"href\") for movie in movies]\n",
    "        return urls\n",
    "    \n",
    "    def extract_movie_info(self):\n",
    "        \"Get a movie's information.\"\n",
    "        self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"dl.movie-info\")))\n",
    "        movie_info = self.driver.find_element(By.CSS_SELECTOR, \"dl.movie-info\")\n",
    "        return movie_info.text\n",
    "           \n",
    "    def extract_movie_rating(self):\n",
    "        \"Get a movie's rating.\"\n",
    "        try:\n",
    "            movie_rating = self.driver.find_element(By.CSS_SELECTOR, \"div#movie-rat-avg\")\n",
    "        except NoSuchElementException:\n",
    "            return \"-1\"\n",
    "        else:\n",
    "            return movie_rating.text\n",
    "    \n",
    "    def write_movie_info(self, file_name):\n",
    "        \"Write movie's info and rating to a file.\"\n",
    "        movie_info = self.extract_movie_info()\n",
    "        movie_rating = self.extract_movie_rating() \n",
    "        with open(file_name, \"a\") as file:\n",
    "            info = (movie_info + \"\\nRating\\n\" + movie_rating).replace(\"\\n\", \"***\")\n",
    "            file.write(info)\n",
    "            file.write(\"\\n\\n\")\n",
    "            \n",
    "    def go_next_page(self):\n",
    "        \"Get the next page in a selection of movies.\"\n",
    "        try: \n",
    "            pager = self.driver.find_element(By.CSS_SELECTOR, \"div.pager\")\n",
    "            next_page = pager.find_element(By.PARTIAL_LINK_TEXT, \">>\")\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        else:\n",
    "            next_page.send_keys(Keys.RETURN)\n",
    "            return True\n",
    "        \n",
    "    def short_scrape(self, country, gender, fromyear, toyear, file_name):\n",
    "        \"Scrape Filmaffinity's database from a small selection (less than 500 movies).\"\n",
    "        self.get_advanced_search()\n",
    "        self.select_country(country)\n",
    "        self.select_genre(gender)\n",
    "        self.select_from_to_year(str(fromyear), str(toyear))\n",
    "        self.search_selection()\n",
    "\n",
    "        repeat = True\n",
    "        while repeat:\n",
    "            urls = self.get_urls()\n",
    "            for url in urls:\n",
    "                self.driver.get(url)\n",
    "                self.write_movie_info(file_name)\n",
    "                self.driver.back()\n",
    "    \n",
    "            repeat = self.go_next_page()\n",
    "        \n",
    "        print(\"Everything was scraped >:)\")\n",
    "    \n",
    "    def long_scrape(self, country, gender, fromyear, toyear, file_name):\n",
    "        \"Scrape Filmaffinity's database from a big selection (more than 500 movies).\"\n",
    "        self.get_advanced_search()\n",
    "        self.select_country(country)\n",
    "        self.select_genre(gender)\n",
    "        years = (str(year) for year in range(fromyear, toyear + 1))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                year = next(years)\n",
    "            except StopIteration:\n",
    "                print(\"Everything was scraped >:)\")\n",
    "                break\n",
    "            self.select_from_to_year(year, year)\n",
    "            self.search_selection()\n",
    "            \n",
    "            repeat = True\n",
    "            while repeat:\n",
    "                urls = self.get_urls()\n",
    "                for url in urls:\n",
    "                    self.driver.get(url)\n",
    "                    self.write_movie_info(file_name)\n",
    "                    self.driver.back()\n",
    "    \n",
    "                repeat = self.go_next_page()\n",
    "        \n",
    "    def verify(self, file_name):\n",
    "        \"Count the number of movies scraped in a file.\"\n",
    "        with open(file_name, \"r\") as file:\n",
    "            everything = file.read()\n",
    "        every_movie = everything.split(\"\\n\\n\")\n",
    "        if \"\" in every_movie:\n",
    "            every_movie.remove(\"\")\n",
    "        return len(every_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FilmaffinityScraper(path = './chromedriver', wait_time = 3)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the scraper.\n",
    "\n",
    "scraper = FilmaffinityScraper()\n",
    "print(scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Available genres.\n",
    "\n",
    "GENRES = {\"Acción\": \"AC\", \n",
    "          \"Animación\": \"AN\", \n",
    "          \"Aventuras\": \"AV\", \n",
    "          \"Bélico\": \"BE\", \n",
    "          \"Ciencia ficción\": \"C-F\", \n",
    "          \"Cine negro\": \"F-N\",\n",
    "          \"Comedia\": \"CO\", \n",
    "          \"Documental\": \"DO\", \n",
    "          \"Drama\": \"DR\", \n",
    "          \"Fantástico\": \"FAN\", \n",
    "          \"Infantil\": \"INF\",\n",
    "          \"Intriga\": \"INT\", \n",
    "          \"Musical\": \"MU\", \n",
    "          \"Romance\": \"RO\", \n",
    "          \"Serie de TV\": \"TV_SE\", \n",
    "          \"Terror\": \"TE\", \n",
    "          \"Thriller\": \"TH\",\n",
    "          \"Western\": \"WE\",\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small search. Getting the urls of a selection.\n",
    "\n",
    "scraper.get_advanced_search()\n",
    "scraper.search_by_text(text=\"cenicienta\")\n",
    "scraper.select_country(\"ES\")\n",
    "scraper.select_genre(\"AN\")\n",
    "scraper.select_from_to_year(\"1950\", \"2020\")\n",
    "scraper.search_selection()\n",
    "urls = scraper.get_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a movie's info and rating in a file.\n",
    "\n",
    "scraper.driver.get(urls[0])\n",
    "scraper.write_movie_info(\"movie_scraping.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was scraped >:)\n"
     ]
    }
   ],
   "source": [
    "# A small scraping is faster when we want to scrape less than 500 movies.\n",
    "\n",
    "scraper.short_scrape(\"ES\", \"WE\", 2008, 2020, \"west_short.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was scraped >:)\n"
     ]
    }
   ],
   "source": [
    "# A big scraping can automatize a big extraction (more than 500 movies).\n",
    "\n",
    "scraper.long_scrape(\"ES\", \"WE\", 2008, 2020, \"west_long.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that both scrapers do the same.\n",
    "\n",
    "scraper.verify(\"west_short.txt\") == scraper.verify(\"west_long.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
